---
title: "Homework 0"
author: "Oviya Mohan & Yue Zhang"
date: "7/19/2022"
output:
  html_document:
    df_print: paged
    toc: yes
  word_document:
    toc: no
  pdf_document:
    latex_engine: xelatex
    number_sections: no
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 
```


## Introduction 

The purpose of this homework is to set the stage for our stats course, get everyone familiar with R and R Markdown and to start a discussion on stats. It will go over some basic statistical concepts, that we have probably already come across often in most introductory statistics courses. If you have any questions, comments or suggestions, feel free to reach out to us. 

Please complete and submit this Rmd by emailing it to either yzh191@u.rochester.edu or omohan@ur.rochester.edu by **11:59 pm** on **Aug 21, 2022**. You can submit just the Rmd but make sure it knits without errors before you do! You can also edit the author and date on top of this document. And make sure to read all the mandatory reading materials provided or Muffin and Pico will hunt you down. There are also a lot of extra resources scattered around, take some time to explore them and if you want to add to them - drop a message on slack and share them! There are both **conceptual questions** and **code chunks** for you to answer and fill out. Trying out extra visualizations and tests are encouraged! Post any syntax or code related doubts on slack as soon as you encounter them so we can work on them together. You are also required to list some questions, of a more conceptual nature, at the end of this document - you will find more details about that below. 


```{r, include = FALSE}
# Installing and loading libraries 
library(tidyverse)
library(dplyr)
library(ggplot2)
library(car)
```

## Resources on R and Rmd
This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document.

RStudio Cloud has great [primers](https://rstudio.cloud/learn/primers) to help you get started with R if you are new to it. It is also recommended that you go through the Chapters 2-5 of the textbook to get more practice with data visualization and wrangling in R. These [cheatsheets](https://rstudio.cloud/learn/cheat-sheets) will also come in handy during out lab sessions as we familiarize ourselves with R. 


## Simulation and NHST
### Simulating Data <a name="data"></a>

```{r}
#nothing is ever truly random when "randomly" generated on a computer - always pseudo random
#set.seed(124) #can be used to get the same "random" sample consistently 
dog_mu = 20
dog_sigma = 5
dog_sample = rnorm(100,dog_mu,dog_sigma)
cat_mu = 15
cat_sigma = 2
cat_sample = rnorm(100,cat_mu,cat_sigma)

#random R tip #1: to view any variable, highlight it and Cmd+enter/Ctrl+enter 

```

### Performing Null Hypothesis Signifiance Testing (NHST) 
From now on, we will pretend that we do not know the true underlying population distribution. Read the following article on NHST: 
[Null Hypothesis Significance Testing: a short tutorial](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5635437/)

1. **Summarizing Data.** Insert two code chunks, 1) to visualize and 2) to calculate and fill out following table on the statistical summary of the simulated [sample data](#data)

```{r}
#visualizing data 
hist_dog <- hist(dog_sample,
main="Distribution of Dog Sizes",
xlab="Size",
col="blue",
alpha = 0.6, 
freq=FALSE,
breaks = 20,
plot = FALSE
)
hist_cat <- hist(cat_sample,
main="Distribution of Cat Sizes",
xlab="Size",
col="orange",
alpha = 0.4, 
freq=FALSE,
breaks = 20,
plot = FALSE
)

# plot two distributions together
plot(hist_dog, col = "blue", xlab = "Size (lb)", main = "Distribution of Dog and Cat Sizes")
plot(hist_cat, col = "orange", add = TRUE)


#try other ways to visualize the data here 

```

```{r}
#summarizing our data  
dog_mean <- mean(dog_sample)
dog_sd <- sd(dog_sample)

cat_mean <- mean(cat_sample)
cat_sd <- sd(cat_sample)
```
| Pets |Mean|Standard Deviation|
|:---:|:---:|:---:|
| Dog |<\br>|<\br>|
| Cat |<\br>|<\br>|

2. **Listing Hypotheses.** We would like to compare the size of dogs with the size of cats. List out the hypotheses: 
    * Null Hypothesis: <\br>
    * Alternate Hypothesis: <\br>
    
3. **Knowing the Assumptions.** In this case, a t-test ![TFormula](images\ttest.png) will be performed to test our hypotheses. There are different types of t-tests - one sample t-test, independent two sample t-test and paired two sample t-test. We are using **independent two sample t-test** because of the nature of our data. Our two samples draw values from *TWO* *INDEPENDENT* samples. 
But before we actually run the test, we have to make sure the following assumptions of the independent two sample t-test are met: 
    - [x] [Independence](#independence)
    - [x] [Normality](#normality)
    - [x] [Homogeneity](#homogeneity)
    
  - *Independence.*<a name="independence"></a> Well, you can either be a cat or a dog. Unless you're Muffin the dog-cat or Pico the cat-dog but let's assume that all our cats are only cats and all our dogs are only dogs. 
  - *Normality.* <a name="normality"></a> Visualizing data using a [Q-Q plot](https://sherrytowers.com/2013/08/29/aml-610-fall-2013-module-ii-review-of-probability-distributions/qqplot_examples/) can be used to check for normality. For n >= 100, Shapiro-Wilk test for normality[^1]. Keep in mind: ["The t-test is described as a robust test with respect to the assumption of normality. This means that some deviation away from normality does not have a large influence on Type I error rates. The exception to this is if the ratio of the smallest to largest group size is greater than 1.5 (largest compared to smallest)."](https://statistics.laerd.com/statistical-guides/independent-t-test-statistical-guide.php)
```{r}
# Visualize normality with a Q-Q plot 
data_frame(val = dog_sample) %>%
          ggplot(., aes(sample = val)) + 
                geom_qq_line() + 
                geom_qq()
data_frame(val = cat_sample) %>%
          ggplot(., aes(sample = val)) + 
                geom_qq_line() + 
                geom_qq()

#Running the Shapiro-Wilk test for normality
shapiro.test(dog_sample)
shapiro.test(cat_sample)
```
[^1]: A p-value of greater than 0.05 from the Shapiro-Wilk test means that our data are NOT significantly different from a normal distribution.

Is the data normality distributed? <\br>  
If the data is not normally distributed, we can either 1) transform data or 2) use a non-parametric, like [Mann-Whitney U Test](https://www.statisticssolutions.com/free-resources/directory-of-statistical-analyses/mann-whitney-u-test/). But as mentioned above, the t-test is robust to some deviation from normality. It is up to you us as researchers to decide how much deviation is acceptable. 

  - *Homogeneity.*<a name="homogeneity"></a> Homogeneity meaning the variances of the two distributions are equal. It can be tested using Levene's Test of Equality of Variance[^2], which gives us a F statistic.
```{r}
#because Levene's test was written for data frames, we will have to wrangle our two vectors into a data frame to get in the required format before running Levene's test 
data_frame <- as.data.frame(cbind(dog_sample, cat_sample))
data_frame <- pivot_longer(data_frame, everything(), names_to = "variable", values_to = "value")
leveneTest(value ~ variable, data_frame)
#NOTE: a lot of the plots and other tests we ran above can be redone in a more efficient and elegant way with our data_frame. Give it a try! 
```
[^2]: A p-value greater than 0.05 means that the two variances are NOT statistically different from each other.

Is the data normality homogeneous? <\br> 
What to do if our variances are not equal? <\br> Correction via the df, which is automatically done in the Welch's t-test by simply setting the var.equal parameter to FALSE in the t.test() function. 


4. **Performing Statistical Testing.** Based on the results of testing the assumptions, what t-test should we do? 
```{r}
# Perform t-test here
t.test(dog_sample,cat_sample,var.equal = TRUE) #The Independent two sample t-test 
t.test(dog_sample,cat_sample,var.equal = FALSE) #The Welch's t-test for nonhomogeneity
```


### Statistical Inferences 
1. **Reporting T-test Results.** How do we convey the results from the t-test to others? Please report the results here:
  - [APA style](https://www.socscistatistics.com/tutorials/ttest/default.aspx): <\br>
  - Explain in your own words what the results mean in relation to our hypotheses: <\br>
  
2. **Understanding P-value.** Before jumping to conclusions based on the results of these tests, it is our responsibility to understand what the p-value, confidence intervals and other metrics seen as the output of the t-test really mean and how we can draw conclusions and influences based on them. 

[What is a p-value](https://www.youtube.com/watch?v=RVxHlsIw_Do) 
[Understanding common misconceptions about p-values](http://daniellakens.blogspot.com/2017/12/understanding-common-misconceptions.html)
Here are some interactive visualizations to play around with in order to truly grasp what a p-value means:
* [Understanding p-values Through Simulations](https://rpsychologist.com/pvalue/)
* [Distribution of p-values when comparing two groups](https://rpsychologist.com/d3/pdist/)

Explain what a p-value is in your own words. <\br> Would you report a result as statistically significant is your p-value was 0.051? What about if it was 0.049? 

3. **Interpreting Confidence Intervals.** They give us more ... confidence? Read [this](https://s4be.cochrane.org/blog/2018/04/27/confidence-intervals-should-be-reported/) to get an idea of why they should be reported. And [here](https://nursing.ucalgary.ca/sites/default/files/teams/3/ExamplesusingAPAFormat.pdf) is an APA guide to reporting them (among other things).
Explain what a confidence interval is in your own words. <\br> And re-write your report of the t-test results but this time include the confidence interval. <\br>

## The Bigger Picture
In this course, we aim to learn more about the application of statistical methods as a tool to make inferences about our data as well as conceptual understanding of these methods commonly used in Brain and Cognitive Sciences. The two main questions we should be able to answer for ourselves at the end are:
1. Given my data set and hypotheses, which set of statistical tests would be the most appropriate?
2. How do I interpret the results from these tests?
3. Are the conclusions and inferences I am drawing from my analysis valid?

Things we would like to keep emphasizing throughout this course are:
1. Know our hypotheses before start performing statistical tests.
2. Prevent [p-hacking](https://www.youtube.com/watch?v=HDCOUXE3HMM)  
<img src="images\phack.png"  width="400" height="300">

Try your hand at some [p-hacking](https://projects.fivethirtyeight.com/p-hacking/)
One thing we can do to overcome this is practice [pre-registration](https://www.cos.io/initiatives/prereg) 
 Would you pre-register a study? Why or why not?
Is that sufficient to curb p-hacking? 


## Questions and Comments 
Below list three questions/comments you have for discussion in the first class based on what you have done above and the readings. At least two of the questions should be conceptual. They can be meta. Please post any syntax/code based doubts on Slack. The questions you list here will be voted on along with questions from others and we will be discussing the most popular questions.  

1. <\br>
2. <\br>
3. <\br> 
