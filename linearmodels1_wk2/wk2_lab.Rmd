---
title: "Linear Models I - Week 2"
author: "Yue Zhang and Oviya Mohan"
date: "8/25/2022"
output:
  html_document: default
  pdf_document: default
---

## Introduction

This dataset looks at the effect of saccade landing errors on the performance of pre-saccadic attention.

## Pre-lab
```{r,warning=FALSE,message=FALSE}
# install and attach libraries
# install.packages("janitor")
library("knitr")      # for knitting RMarkdown 
#library("kableExtra") # for making nice tables
library("janitor")    # for cleaning column names
library("broom")      # for tidying up linear models 
library("tidyverse")  # for wrangling, plotting, etc. 
```

## Step1: Hypotheses

$H_{0}$ =

$H_{1}$ =

## Step2: Visualize data and find correlation

```{r}
#load data
dataframe <- read.csv("msData.csv") 
#plot data
ggplot(data = dataframe,
       aes(x = dist,
           y = rt)) +
  geom_point(size = 1)
```

```{r}
# find correlation 

```

## Step3: Fit Models

### Define and fit the compact model (Model C):

$$Y_{i} = \beta_{0} + \epsilon_{i}$$

```{r}
# fit the compact model
lm.compact = lm(rt ~ 1, data = dataframe)

# store the results of the model fit in a data frame
df.compact = tidy(lm.compact)

# plot the data with model prediction
ggplot(data = dataframe,
       aes(x = dist,
           y = rt)) +
  geom_hline(yintercept = df.compact$estimate,
             color = "red",
              size = 1) +
  geom_point(size = 1, shape = 5) 
```

### Define and fit the augmented model (Model A):

$$Y_{i} = \beta_{0} + \beta_{1}X_{i}+ \epsilon_{i}$$

```{r}
# fit the augmented model
lm.augmented = lm(rt ~ dist, data = dataframe)

# store the results of the model fit in a data frame
df.augmented = tidy(lm.augmented)

# plot the data with model prediction
ggplot(data = dataframe,
       aes(x = dist,
           y = rt)) +
  geom_abline(intercept = df.augmented$estimate[1],
              slope = df.augmented$estimate[2],
              color = "blue",
              size = 1) +
  geom_point(size = 1, shape = 5) 
```

## Step4: Compare Models

### Caluclate residuals and SSE of Model C
```{r}
# create a data frame that contains the residuals 
df.compact_model = augment(lm.compact) %>% 
  clean_names() %>% 
  left_join(dataframe, by = "rt")

# plot model prediction with residuals
ggplot(data = df.compact_model,
       aes(x = dist,
           y = rt)) +
  geom_hline(yintercept = df.compact$estimate,
             color = "red",
              size = 1) +
  geom_segment(aes(xend = dist,
                   yend = df.compact$estimate),
               color = "red") + 
  geom_point(size = 1, shape = 5) 

# calculate the sum of squared errors
df.compact_model %>% 
  summarize(SSE = sum(resid^2))
```

### Caluclate residuals and SSE of Model A
```{r}

# create a data frame that contains the residuals 
df.augmented_model = augment(lm.augmented) %>% 
  clean_names() %>% 
  left_join(dataframe, by = c("rt", "dist"))

# plot model prediction with residuals
ggplot(data = df.augmented_model,
       aes(x = dist,
           y = rt)) +
  geom_abline(intercept = df.augmented$estimate[1],
              slope = df.augmented$estimate[2],
             color = "blue",
              size = 1) +
  geom_segment(aes(xend = dist,
                   yend = fitted),
               color = "blue") + 
  geom_point(size = 1, shape = 5) 

# calculate the sum of squared errors
df.augmented_model %>% 
  summarize(SSE = sum(resid^2))
```

### Calculate the F statistic to determine whether PRE (Proportion Reduction in Error) is significant
```{r}
pc = 1 # number of parameters in the compact model  
pa = 2 # number of parameters in the augmented model  
n = 1051 # number of observations

# SSE of the compact model 
sse_compact = df.compact_model %>% 
  summarize(SSE = sum(resid^2))

# SSE of the augmented model
sse_augmented = df.augmented_model %>% 
  summarize(SSE = sum(resid^2))

# Proportional reduction of error 
pre = as.numeric(1 - (sse_augmented/sse_compact))

# F-statistic 
f = (pre/(pa-pc))/((1-pre)/(n-pa))

# p-value
p_value = 1-pf(f, df1 = pa-pc, df2 = n-pa)
print(p_value)

# plot f stats on f distribution
ggplot(data = tibble(x = c(0, 10)),
       mapping = aes(x = x)) +
  stat_function(fun = "df",
                args = list(df1 = pa-pc,
                            df2 = n-pa),
                size = 1) +
  geom_vline(xintercept = f,
             color = "red",
             size = 1)
```

## Step5: Reporting Results
```{r}
summary(lm.augmented)
```
Reporting statistical test results:
Conclusion: 


